{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "\n",
    "1. [Background](#1)\n",
    "2. [Setup the Environment](#2)\n",
    "3. [Prepare the Data](#3)\n",
    "4. [Algorithm Comparison](#4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=1></a> 1. Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time series forecast is a very common problem in many real-world applications. A wide spectrum of algorithms have been proposed to solve this problem. However, it is usually difficult to benchmark different algorithms and compare their performance due to the various implementation of the algorithms. This notebook tries to show an example how to benchmark different time series forecast algorithms by only using the Glutonts library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=2></a> 2. Setup the Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 install R for extenal r forecast algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intall the missing lib for R\n",
    "!sudo yum install libXt-1.1.4-6.1.9.amzn1.x86_64 -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# install python r interface\n",
    "!conda install -c r rpy2==2.9.4 --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# install forecast R packages\n",
    "!R -e 'install.packages(c(\"forecast\", \"nnfor\"), repos=\"https://cloud.r-project.org\")'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Install Python Pacakages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# install Prophet python packages\n",
    "!conda install -c plotly plotly==3.10.0 --yes\n",
    "!conda install -c conda-forge fbprophet=0.5=py36he1b5a44_0 --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c anaconda ujson=1.35=py36h14c3975_0 --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# install gluonts\n",
    "!pip install gluonts==0.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install mxnet\n",
    "!pip install mxnet==1.4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys\n",
    "import zipfile\n",
    "import mxnet as mx\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "from gluonts.model.trivial.mean import MeanPredictor\n",
    "from gluonts.model.seasonal_naive import SeasonalNaivePredictor\n",
    "from gluonts.model.r_forecast import RForecastPredictor\n",
    "from gluonts.model.prophet import ProphetPredictor\n",
    "from gluonts.model.deepar import DeepAREstimator\n",
    "from gluonts.trainer import Trainer\n",
    "from gluonts.dataset.common import ListDataset\n",
    "from itertools import islice\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "from gluonts.evaluation import Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix some plot issues caused by Prophet model\n",
    "# pls refer to https://darektidwell.com/typeerror-float-argument-must-be-a-string-or-a-number-not-period-facebook-prophet-and-pandas/\n",
    "pd.plotting.register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## supress output\n",
    "#import logging\n",
    "#logger = logging.getLogger()\n",
    "#logger.setLevel(logging.CRITICAL)\n",
    "#import warnings\n",
    "#warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "mx.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=3></a> 3. Prepare the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import electricity dataset, we need to download the original data set of from the UCI data set repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_HOST = \"https://archive.ics.uci.edu\"\n",
    "DATA_PATH = \"/ml/machine-learning-databases/00321/\"\n",
    "ARCHIVE_NAME = \"LD2011_2014.txt.zip\"\n",
    "FILE_NAME = ARCHIVE_NAME[:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progress_report_hook(count, block_size, total_size):\n",
    "    mb = int(count * block_size // 1e6)\n",
    "    if count % 500 == 0:\n",
    "        sys.stdout.write(\"\\r{} MB downloaded\".format(mb))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "if not os.path.isfile(FILE_NAME):\n",
    "    print(\"downloading dataset (258MB), can take a few minutes depending on your connection\")\n",
    "    urlretrieve(DATA_HOST + DATA_PATH + ARCHIVE_NAME, ARCHIVE_NAME, reporthook=progress_report_hook)\n",
    "\n",
    "    print(\"\\nextracting data archive\")\n",
    "    zip_ref = zipfile.ZipFile(ARCHIVE_NAME, 'r')\n",
    "    zip_ref.extractall(\"./\")\n",
    "    zip_ref.close()\n",
    "else:\n",
    "    print(\"File found skipping download\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(FILE_NAME, sep=\";\", index_col=0, parse_dates=True, decimal=',')\n",
    "num_timeseries = data.shape[1]\n",
    "data_kw = data.resample('2H').sum() / 8\n",
    "timeseries = []\n",
    "for i in range(num_timeseries):\n",
    "    timeseries.append(np.trim_zeros(data_kw.iloc[:,i], trim='f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(5, 2, figsize=(20, 20), sharex=True)\n",
    "axx = axs.ravel()\n",
    "for i in range(0, 10):\n",
    "    timeseries[i].loc[\"2014-01-01\":\"2014-01-14\"].plot(ax=axx[i])\n",
    "    axx[i].set_xlabel(\"date\")    \n",
    "    axx[i].set_ylabel(\"kW consumption\")   \n",
    "    axx[i].grid(which='minor', axis='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Train Test Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_data(timeseries,\n",
    "                          start_dataset,\n",
    "                          end_training,\n",
    "                          num_test_windows):\n",
    "    # create training data.\n",
    "    training_data = [\n",
    "    {\n",
    "        \"start\": str(start_dataset),\n",
    "        \"target\": ts[start_dataset:end_training - 1].tolist(),  # We use -1, because pandas indexing includes the upper bound\n",
    "        \"feat_static_cat\": [id]\n",
    "    }\n",
    "    for id, ts in enumerate(timeseries)\n",
    "    ]\n",
    "    \n",
    "    # create testing data.\n",
    "    test_data = [\n",
    "        {\n",
    "            \"start\": str(start_dataset),\n",
    "            \"target\": ts[start_dataset:end_training + k * prediction_length].tolist(),\n",
    "            \"feat_static_cat\": [id]\n",
    "        }\n",
    "        for k in range(1, num_test_windows + 1)\n",
    "        for id, ts in enumerate(timeseries)\n",
    "    ]\n",
    "    \n",
    "    return training_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use 2 hour frequency for the time series\n",
    "freq = '2H'\n",
    "\n",
    "# we predict for 1 day\n",
    "prediction_length = 1 * 12\n",
    "\n",
    "# we also use 7 days as context length, this is the number of state updates accomplished before making predictions\n",
    "context_length = 7 * 12\n",
    "\n",
    "# The moving window for forecast\n",
    "num_test_windows = 1\n",
    "\n",
    "# training/test Split\n",
    "start_dataset = pd.Timestamp(\"2014-01-01 00:00:00\", freq=freq)\n",
    "end_training = pd.Timestamp(\"2014-09-01 00:00:00\", freq=freq)\n",
    "\n",
    "# number of time series selected\n",
    "n_timeseries = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, test_data = split_train_test_data(timeseries[:n_timeseries],\n",
    "                          start_dataset,\n",
    "                          end_training,\n",
    "                          num_test_windows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=4></a> 4. Algorithm Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(training_data, \n",
    "                   test_data,\n",
    "                   freq,\n",
    "                   num_test_windows,\n",
    "                   model,\n",
    "                   train_per_ts=False,\n",
    "                   require_train=False\n",
    "                   ):\n",
    "    forecasts = []\n",
    "    tss = []\n",
    "    # if training per time series is required.\n",
    "    if train_per_ts:\n",
    "        # iterate over the timeseries\n",
    "        count = 0\n",
    "        for training_ts in training_data:\n",
    "            # get the training time series\n",
    "            training_ts = ListDataset(\n",
    "                      [training_ts],\n",
    "                      freq = freq\n",
    "            )\n",
    "            # get the related testing time series\n",
    "            test_tss = test_data[count*num_test_windows: (count+1)*num_test_windows]\n",
    "\n",
    "            test_tss = ListDataset(\n",
    "                test_tss,\n",
    "                freq = freq\n",
    "            )\n",
    "            if require_train:\n",
    "                predictor = model.train(training_data=training_ts)\n",
    "            else:\n",
    "                predictor = model\n",
    "            \n",
    "            forecast_it, ts_it = make_evaluation_predictions(test_tss, predictor=predictor, num_samples=100)\n",
    "            forecasts.extend(list(forecast_it))\n",
    "            tss.extend(list(ts_it))\n",
    "            count += 1\n",
    "    else:\n",
    "        training_data = ListDataset(\n",
    "                      training_data,\n",
    "                      freq = freq\n",
    "            )\n",
    "        test_data = ListDataset(\n",
    "            test_data,\n",
    "            freq = freq\n",
    "        )\n",
    "        if require_train:\n",
    "            predictor = model.train(training_data=training_data)\n",
    "        else:\n",
    "            predictor = model\n",
    "        \n",
    "        forecast_it, ts_it = make_evaluation_predictions(test_data, predictor=predictor, num_samples=100)\n",
    "        forecasts.extend(list(forecast_it))\n",
    "        tss.extend(list(ts_it))\n",
    "        \n",
    "    return forecasts, tss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mean= MeanPredictor(freq=freq, prediction_length=prediction_length,\n",
    "                                  context_length=context_length)\n",
    "forecasts_mean, tss_mean = train_and_test(training_data, \n",
    "               test_data,\n",
    "               freq,\n",
    "               num_test_windows,\n",
    "               mean,\n",
    "               train_per_ts=True,\n",
    "               require_train=False\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seaonal Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "seasonal = SeasonalNaivePredictor(freq=freq,\n",
    "                                  prediction_length=prediction_length,\n",
    "                                  season_length=context_length)\n",
    "forecasts_seasonal, tss_seasonal = train_and_test(training_data, \n",
    "               test_data,\n",
    "               freq,\n",
    "               num_test_windows,\n",
    "               seasonal,\n",
    "               train_per_ts=True,\n",
    "               require_train=False\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "arima = RForecastPredictor(freq=freq,\n",
    "                           prediction_length=prediction_length,\n",
    "                           method_name='arima')\n",
    "forecasts_arima, tss_arima = train_and_test(training_data, \n",
    "               test_data,\n",
    "               freq,\n",
    "               num_test_windows,\n",
    "               arima,\n",
    "               train_per_ts=True,\n",
    "               require_train=False\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "prophet = ProphetPredictor(freq, prediction_length)\n",
    "forecasts_prophet, tss_prophet = train_and_test(training_data, \n",
    "               test_data,\n",
    "               freq,\n",
    "               num_test_windows,\n",
    "               prophet,\n",
    "               train_per_ts=True,\n",
    "               require_train=False\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "deepar = DeepAREstimator(freq=freq,\n",
    "                         use_feat_static_cat=True,\n",
    "                         cardinality=[n_timeseries],\n",
    "                        prediction_length=prediction_length,\n",
    "                        trainer=Trainer(epochs=100),\n",
    "                        num_cells=40)\n",
    "forecasts_deepar, tss_deepar = train_and_test(training_data, \n",
    "               test_data,\n",
    "               freq,\n",
    "               num_test_windows,\n",
    "               deepar,\n",
    "               train_per_ts=False,\n",
    "               require_train=True\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(quantiles=[0.5], seasonality=None)\n",
    "agg_metrics_mean, item_metrics_mean = evaluator(iter(tss_mean), iter(forecasts_mean), num_series=len(forecasts_mean))\n",
    "print(agg_metrics_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(quantiles=[0.5], seasonality=None)\n",
    "agg_metrics_seasonal, item_metrics_seasonal = evaluator(iter(tss_seasonal), \n",
    "                                                        iter(forecasts_seasonal), \n",
    "                                                        num_series=len(forecasts_seasonal))\n",
    "print(agg_metrics_seasonal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(quantiles=[0.5], seasonality=None)\n",
    "agg_metrics_arima, item_metrics_arima = evaluator(iter(tss_arima), \n",
    "                                                        iter(forecasts_arima), \n",
    "                                                        num_series=len(forecasts_arima))\n",
    "print(agg_metrics_arima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(quantiles=[0.5], seasonality=None)\n",
    "agg_metrics_prophet, item_metrics_prophet = evaluator(iter(tss_prophet), \n",
    "                                                        iter(forecasts_prophet), \n",
    "                                                        num_series=len(forecasts_prophet))\n",
    "print(agg_metrics_prophet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(quantiles=[0.5], seasonality=None)\n",
    "agg_metrics_deepar, item_metrics_deepar = evaluator(iter(tss_deepar), \n",
    "                                                        iter(forecasts_deepar), \n",
    "                                                        num_series=len(forecasts_deepar))\n",
    "print(agg_metrics_deepar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = pd.concat(\n",
    "    [\n",
    "        pd.DataFrame.from_dict(agg_metrics_deepar, orient='index').rename(columns={0: \"DeepAR\"}),\n",
    "     pd.DataFrame.from_dict(agg_metrics_prophet, orient='index').rename(columns={0: \"Prophet\"}),\n",
    "     pd.DataFrame.from_dict(agg_metrics_arima, orient='index').rename(columns={0: \"ARIMA\"}),\n",
    "    pd.DataFrame.from_dict(agg_metrics_seasonal, orient='index').rename(columns={0: \"Seasonal naive\"}),\n",
    "    pd.DataFrame.from_dict(agg_metrics_mean, orient='index').rename(columns={0: \"Mean\"})], axis=1\n",
    ")\n",
    "df_metrics.loc[[\"MASE\", \"RMSE\", \"sMAPE\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Example Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forecasts(tss, forecasts, past_length, start, stop, step, title):\n",
    "    for target, forecast in islice(zip(tss, forecasts), start, stop, step):\n",
    "        ax = target[-past_length:].plot(figsize=(12, 5), linewidth=2)\n",
    "        forecast.plot(color='g')\n",
    "        plt.title(title)\n",
    "        plt.grid(which='both')\n",
    "        plt.legend([\"observations\", \"median prediction\", \"90% confidence interval\", \"50% confidence interval\"])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start, stop, step = 10, 11, 1\n",
    "plot_forecasts(tss_mean, forecasts_mean, past_length=100, start=start, stop=stop, step=step, title=\"mean\")\n",
    "plot_forecasts(tss_seasonal, forecasts_seasonal, past_length=100, start=start, stop=stop, step=step, title=\"seasonal\")\n",
    "plot_forecasts(tss_arima, forecasts_arima, past_length=100, start=start, stop=stop, step=step, title=\"arima\")\n",
    "plot_forecasts(tss_prophet, forecasts_prophet, past_length=100, start=start, stop=stop, step=step, title=\"prophet\")\n",
    "plot_forecasts(tss_deepar, forecasts_deepar, past_length=100, start=start, stop=stop, step=step, title=\"deepar\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
